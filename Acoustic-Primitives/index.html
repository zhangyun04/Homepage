<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Acoustic Primitives">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Acoustic Primitives</title>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <!-- <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script> -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
            <h1 class="title is-2 publication-title"><span style="color: rgb(54, 54, 54);">Modeling  and Driving Human Body Soundfields through <span class="gradient-text">Acoustic Primitives</span></span> </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://wikichao.github.io/" target="_blank" class="author-text">
                  Chao Huang
                  <span class="text-star">1</span>
                </a>,
                <a href="https://scholar.google.com/citations?user=cyAYD3UAAAAJ&hl=en" target="_blank" class="author-text">
                Dejan Markovic
                <span class="text-star">2</span>
                </a>,
                <a href="https://www.cs.rochester.edu/~cxu22/" target="_blank" class="author-text">
                  Chenliang Xu
                  <span class="text-star">1</span>
                </a>,
                <a href="https://alexanderrichard.github.io/" target="_blank" class="author-text">
                    Alexander Richard
                    <span class="text-star">2</span>
                </a>
              </span>
              <span class="author-block">
                <p><span class="text-star">1</span>University of Rochester, Rochester, NY &nbsp; &nbsp; <span class="text-star">2</span>Codec Avatars Lab, Meta, Pittsburgh, PA</p>
              </span>
            </div>

          <h2 class="title is-4 publication-title" style="color: rgb(170, 0, 0); margin-top: 20px; margin-bottom: 5px;">ECCV 2024</h2>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2407.13083" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
          <!-- <h1 class="tldr column has-text-centered">
            <b>tl;dr</b>:
            We propose Acoustic Primitives -- smaller and compact soundfield representations similar to volumetric primitives in computer graphics
          </h1> -->
        </div>

      </div>
    </div>
  </div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While rendering and animation of photorealistic 3D human body models have matured and reached an impressive quality over the past years, modeling the spatial audio associated with such full body models has been largely ignored so far.
            In this work, we present a framework that allows for high-quality spatial audio generation, capable of rendering the full 3D soundfield generated by a human body, including speech, footsteps, hand-body interactions, and others.
            Given a basic audio-visual representation of the body in form of 3D body pose and audio from a head-mounted microphone, we demonstrate that we can render the full acoustic scene at any point in 3D space efficiently and accurately.
            To enable near-field and realtime rendering of sound, we borrow the idea of volumetric primitives from graphical neural rendering and transfer them into the acoustic domain.
            Our acoustic primitives result in an order of magnitude smaller soundfield representations and overcome deficiencies in near-field rendering compared to previous approaches.
          </p>

        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <div class="centered-figure">
            <img src="./data/teaser.jpg">
          </div>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
          <!-- <video id="replay-video"
                  controls
                  preload
                  playsinline
                  width="100%">
             <source src="./static/videos/video_demo.mp4"
                     type="video/mp4">
           </video> -->
        <!-- </div> -->
      <!-- </div> -->
    <!-- </div> -->
    <!--/ Paper video. -->
  <!-- </div> -->
</section>


<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Pose-Guided Soundfields Generation</h2>
        <div class="content has-text-justified">
          <p>
            We translate the task of modeling 3D soundfields for the visual body to learning a set of small acoustic primitives \( \{\mathcal{S}_i\}_{i=1}^{K} \), with \( N=2 \) for soundfield coefficients and number of acoustic primitives as \( K \). We decompose the entire learning process into two sub-steps:
            <br><br>
            1) First, we design a neural network \( \mathcal{F} \) that consumes audio and pose data as input, and output the soundfield representation, along with primitive weights to reweight the importance of different acoustic primitives and offsets to adjust the sound source locations
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <div class="centered-figure">
            <img src="./data/framworkv2.png">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            2) With the learned acoustic primitives \( \{\mathcal{S}_i\}_{i=1}^{K} \), we leverage a differentiable rendering function, denoted as \( \mathcal{R} \) (illustrated in the paper Eq. (4)), to generate the audio waveform received at the target position
          </p>

        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <div class="centered-figure">
            <img src="./data/rendering.png">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<br><br>

<section>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-4">Visualizations of Learned Acoustic Primitives</h2>
        <div class="content has-text-justified">
          <p>
            Sound field visualizations for four different types of sounds are shown, with the main sound field in the center and individual primitive contributions around it. The method correctly assigns acoustic energy to relevant primitives, e.g., speech is primarily from the head with minimal contribution from the shoulders, and the directivity matches the head's orientation. In each visualization, the left and right primitives, from bottom to top, are labeled <b><i>foot</i></b>, <b><i>hip</i></b>, <b><i>hand</i></b>, and <b><i>shoulder</i></b>, with the <b><i>head</i></b> in the middle.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified slider-container">
            <div class="slider-images" style="margin-bottom: 20px;">
              <img src="./data/speech.png" class="active" alt="Speech" style="max-width: 100%; height: auto;">
              <img src="./data/body_tapping.png" alt="Body Tapping" style="max-width: 100%; height: auto;">
              <img src="./data/feet_tapping.png" alt="Feet Tapping" style="max-width: 100%; height: auto;">
              <img src="./data/clapping.png" alt="Clapping" style="max-width: 100%; height: auto;">
            </div>
        </div>
      </div>
    </div>
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="slider-controls">
            <button class="button is-primary" id="prev">
              <span class="icon">
                <i class="fas fa-chevron-left"></i>
              </span>
            </button>
            <div class="slider-wrapper" style="flex-grow: 1; margin: 0 10px;">
              <input type="range" id="imageSlider" min="0" max="3" value="0" class="slider" style="width: 100%;">
              <div class="slider-labels" style="display: flex; justify-content: space-between; margin-top: 5px;">
                <span>Speech</span>
                <span>Body Tapping</span>
                <span>Feet Tapping</span>
                <span>Clapping</span>
              </div>
            </div>
            <button class="button is-primary" id="next">
              <span class="icon">
                <i class="fas fa-chevron-right"></i>
              </span>
            </button>
          </div>
        <p id="imageName" style="margin-top: 10px;">Speech</p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    If you find our work helpful, please consider citing:
    <pre><code>@inproceedings{huang2024modeling,
      author    = {Huang, Chao and
                   Markovic, Dejan and
                   Xu, Chenliang and
                   Richard, Alexander},
      title     = {Modeling and Driving Human Body Soundfields through Acoustic Primitives},
      booktitle = {European Conference on Computer Vision},
      year      = {2024},
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
          <p>
            We thank <a href="https://github.com/nerfies/nerfies.github.io" target="_blank">Nerfies</a> for open sourcing this website template.
          </p>
    </div>
  </div>
</footer>

</body>
</html>
